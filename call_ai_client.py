import asyncio
import json
import logging
import os
import datetime
import wave
import uuid
import argparse
import requests
from dotenv import load_dotenv
from pathlib import Path
from pydub import AudioSegment
import random
import websocket
import time
from minicpm_client import MiniCPMClient
import librosa
import base64


# åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger("ai_client")

# å…¨å±€å˜é‡
AUDIO_DIR = os.getenv("AUDIO_DIR", "audio_files")
PROCESSED_DIR = os.getenv("PROCESSED_DIR", "processed_files")
WS_URL = os.getenv("WS_URL", "ws://stream.kalaisai.com:80/ws/call")
MINICPM_URL = os.getenv("MINICPM_URL", "http://127.0.0.1:32551")

# æœ¬åœ°æœåŠ¡æ¥å£URL
API_URL = "http://127.0.0.1:8000/api/v1"
SPEECH_TO_TEXT_URL = f"{API_URL}/speech-to-text"
MEGATTS_URL = f"http://127.0.0.1:5000/process"
F5TTS_URL = f"http://127.0.0.1:7860/"

QWEN_CHAT_URL = f"{API_URL}/chat/qwen"
UNCENSORED_CHAT_URL = f"{API_URL}/chat/uncensored"

# çŠ¶æ€æ¥å£URL
SPEECH_TO_TEXT_STATUS_URL = f"{API_URL}/speech-to-text/status"
MEGATTS_STATUS_URL = f"{API_URL}/megatts/status"
QWEN_CHAT_STATUS_URL = f"{API_URL}/qwen/status"
UNCENSORED_CHAT_STATUS_URL = f"{API_URL}/uncensored/status"

# ä¼šè¯å†å²è®°å½•
conversation_history = []

# å…¨å±€å˜é‡
AUDIO_CATEGORIES = {}

# å…¨å±€é…ç½®å˜é‡
USE_MINICPM = False
SKIP_TTS = False
USE_F5TTS = False
USE_UNCENSORED = False

# WebSocketç›¸å…³é…ç½®
WS_HEARTBEAT_INTERVAL = 10  # å¿ƒè·³é—´éš”ï¼ˆç§’ï¼‰
WS_RECONNECT_DELAY = 5  # é‡è¿å»¶è¿Ÿï¼ˆç§’ï¼‰
WS_MAX_RETRIES = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
WS_CHUNK_SIZE = 4096  # æ•°æ®åˆ†å—å¤§å°
WS_SEND_TIMEOUT = 30  # å‘é€è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰


def setup_directories():
    """ç¡®ä¿å¿…è¦çš„ç›®å½•å­˜åœ¨"""
    os.makedirs(AUDIO_DIR, exist_ok=True)
    os.makedirs(PROCESSED_DIR, exist_ok=True)
    logger.info(f"å·²åˆ›å»ºç›®å½•: {AUDIO_DIR}, {PROCESSED_DIR}")

def base64_to_wav(base64_audio_data, volume_gain=2.0):
    """è§£ç base64éŸ³é¢‘WAVæ•°æ®"""
    volume_gain = max(0.1, min(volume_gain, 5.0))
    
    try:
        audio_bytes = base64.b64decode(base64_audio_data)
    except Exception as e:
        print(f"Base64è§£ç å¤±è´¥: {e}")
        return None, None, None
    
    return audio_bytes, 24000, 1
            

def on_audio_done(audio_base64):
    global ws, session_id_bytes

    audio_chunks = base64_to_wav(audio_base64)

    if len(audio_chunks[0]) > 0:
        audio_bytes = audio_chunks[0]
    else:
        logger.error("æ— æ³•å°†éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºå­—èŠ‚æ ¼å¼")
        return
    # å¦‚æœsample_rateä¸æ˜¯8000ï¼Œåˆ™é‡é‡‡æ ·åˆ°8000
    # if sample_rate != 8000:
    #     audio_chunks = librosa.resample(audio_chunks, orig_sr=sample_rate, target_sr=8000)

    # å‘é€éŸ³é¢‘å›å¤ - åˆ†å—å‘é€
    chunk_size = WS_CHUNK_SIZE
    total_chunks = (len(audio_bytes) + chunk_size - 1) // chunk_size
    
    for i in range(0, len(audio_bytes), chunk_size):
        # æˆªå–ä¸€å—éŸ³é¢‘æ•°æ®
        audio_chunk = audio_bytes[i:i+chunk_size]
        # å‘é€æ•°æ®å—
        if not send_audio_chunk(ws, session_id_bytes, audio_chunk):
            logger.error(f"å‘é€éŸ³é¢‘æ•°æ®å—å¤±è´¥: {i//chunk_size + 1}/{total_chunks}")
            break
        logger.info(f"ğŸ“¤ å‘é€éŸ³é¢‘å—: {i//chunk_size + 1}/{total_chunks}, å¤§å°: {len(audio_chunk)} å­—èŠ‚")
        # çŸ­æš‚æš‚åœï¼Œé¿å…å‘é€è¿‡å¿«
        time.sleep(0.05)


def on_text_done(text):
    """å¤„ç†æ¥æ”¶åˆ°çš„æ–‡æœ¬æ•°æ®"""
    logger.info(f"ğŸ’¬ æ”¶åˆ°æ–‡æœ¬: {text}")
    # è¿™é‡Œå¯ä»¥æ·»åŠ æ–‡æœ¬å¤„ç†é€»è¾‘ï¼Œæ¯”å¦‚å‘é€åˆ°WebSocketç­‰


def check_service_status(reference_audio_file):
    global minicpm_client
    """æ£€æŸ¥æœ¬åœ°æœåŠ¡æ¥å£çš„çŠ¶æ€"""
    try:
        # æ£€æŸ¥MiniCPMæœåŠ¡çŠ¶æ€
        if USE_MINICPM:
            minicpm_client = MiniCPMClient(base_url=MINICPM_URL)
            response = minicpm_client.check_service_status()
            if response.status_code == 200:
                logger.info(f"MiniCPMæœåŠ¡çŠ¶æ€: {response.json()}")
                minicpm_client.init_with_custom_vad_threshold(reference_audio_file, 0.7)
                minicpm_client.start_completions_listener(on_audio_done=on_audio_done, on_text_done=on_text_done)
            else:
                logger.error(f"MiniCPMæœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥: {response.status_code}")
                return False

        else:
            # æ£€æŸ¥èŠå¤©æœåŠ¡çŠ¶æ€
            if USE_UNCENSORED:
                response = requests.get(UNCENSORED_CHAT_STATUS_URL)
                if response.status_code == 200:
                    logger.info(f"æœªå®¡æ ¸èŠå¤©æœåŠ¡çŠ¶æ€: {response.json()}")
                else:
                    logger.error(f"æœªå®¡æ ¸èŠå¤©æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥: {response.status_code}")
                    return False
            else:
                response = requests.get(QWEN_CHAT_STATUS_URL)
                if response.status_code == 200:
                    logger.info(f"QwenèŠå¤©æœåŠ¡çŠ¶æ€: {response.json()}")
                else:
                    logger.error(f"QwenèŠå¤©æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥: {response.status_code}")
                    return False

            # æ£€æŸ¥è¯­éŸ³è½¬æ–‡å­—æœåŠ¡çŠ¶æ€
            response = requests.get(SPEECH_TO_TEXT_STATUS_URL)
            if response.status_code == 200:
                logger.info(f"è¯­éŸ³è½¬æ–‡å­—æœåŠ¡çŠ¶æ€: {response.json()}")
            else:
                logger.error(f"è¯­éŸ³è½¬æ–‡å­—æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥: {response.status_code}")
                return False

    except Exception as e:
        logger.error(f"æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥: {e}")
        return False

    return True

def speech_to_text(audio_path):
    """è°ƒç”¨æœ¬åœ°æœåŠ¡æ¥å£å°†è¯­éŸ³è½¬æ¢ä¸ºæ–‡æœ¬"""
    try:
        logger.info(f"å¼€å§‹è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚: {audio_path}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(audio_path):
            logger.error(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")
            return None
            
        # è®°å½•æ–‡ä»¶å¤§å°
        file_size = os.path.getsize(audio_path)
        logger.info(f"éŸ³é¢‘æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚")
        
        with open(audio_path, 'rb') as audio_file:
            # ä¸ºæ–‡ä»¶æŒ‡å®šåç§°ã€å†…å®¹ç±»å‹å’Œæ–‡ä»¶å¯¹è±¡
            files = {
                'file': (os.path.basename(audio_path), 
                         audio_file, 
                         'audio/wav')  # æŒ‡å®š MIME ç±»å‹ä¸º audio/wav
            }
            
            headers = {
                'Accept': 'application/json'
            }
            
            logger.info(f"å‘é€è¯·æ±‚åˆ°: {SPEECH_TO_TEXT_URL}")
            logger.info(f"è¯·æ±‚å¤´: {headers}")
            logger.info(f"æ–‡ä»¶å: {os.path.basename(audio_path)}")
            
            response = requests.post(SPEECH_TO_TEXT_URL, files=files, headers=headers)
            
            logger.info(f"æ”¶åˆ°å“åº”: çŠ¶æ€ç ={response.status_code}")
            
            if response.status_code == 200:
                result = response.json()
                # æ ¹æ®å®é™…çš„è¿”å›æ ¼å¼è§£æ
                if result.get("code") == 0:
                    transcription = result.get("data", {}).get("transcription", "")
                    language = result.get("data", {}).get("language", "")
                    logger.info(f"è¯­éŸ³è½¬æ–‡å­—æˆåŠŸï¼Œç»“æœ: {transcription}, è¯­è¨€: {language}")
                    return transcription
                else:
                    logger.error(f"APIè¿”å›é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                    return None
            else:
                logger.error(f"è¯­éŸ³è½¬æ–‡å­—å¤±è´¥: çŠ¶æ€ç ={response.status_code}, å“åº”å†…å®¹={response.text}")
                return None
    except Exception as e:
        logger.error(f"è¯­éŸ³è½¬æ–‡å­—æ¥å£è°ƒç”¨å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return None

def get_chat_response(prompt):
    """è°ƒç”¨èŠå¤©æ¥å£è·å–å›å¤ï¼Œæ ¹æ®é…ç½®é€‰æ‹©Qwenæˆ–Deepseek"""
    global conversation_history
    
    model_name = "Uncensored" if USE_UNCENSORED else "Qwen"
    url = UNCENSORED_CHAT_URL if USE_UNCENSORED else QWEN_CHAT_URL

    try:
        data = {
            "prompt": prompt,
            "history": conversation_history,
            "max_length": 2048,
            "temperature": 0.7,
            "top_p": 0.9
        }
        
        logger.info(f"å‘é€èŠå¤©è¯·æ±‚åˆ°{model_name}ï¼Œprompt: {prompt[:50]}...")
        response = requests.post(url, json=data)
        
        if response.status_code == 200:
            result = response.json()
            
            # æ­£ç¡®è§£æAPIè¿”å›æ ¼å¼
            if result.get("code") == 0:
                # ä»data.responseä¸­è·å–åŠ©æ‰‹å›å¤
                assistant_response = result.get("data", {}).get("response", "")
                logger.info(f"{model_name}èŠå¤©è¯·æ±‚æˆåŠŸï¼Œå›å¤: {assistant_response[:50]}...")
                return assistant_response
            else:
                logger.error(f"{model_name} APIè¿”å›é”™è¯¯: {result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                return None
        else:
            logger.error(f"{model_name}èŠå¤©æ¥å£è°ƒç”¨å¤±è´¥: çŠ¶æ€ç ={response.status_code}, å“åº”å†…å®¹={response.text}")
            return None
    except Exception as e:
        logger.error(f"{model_name}èŠå¤©æ¥å£è°ƒç”¨å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return None

def text_to_speech(text, reference_audio_file):
    """è°ƒç”¨æœ¬åœ°æœåŠ¡æ¥å£å°†æ–‡æœ¬è½¬æ¢ä¸ºè¯­éŸ³"""
    try:
        logger.info(f"å‘é€æ–‡å­—è½¬è¯­éŸ³è¯·æ±‚: æ–‡æœ¬é•¿åº¦={len(text)}, å‚è€ƒéŸ³é¢‘={reference_audio_file}")
        
        data = {
            "wav_path": reference_audio_file,
            "input_text": text,
            "output_dir": "/data/MegaTTS3/output",
        }
        
        response = requests.post(MEGATTS_URL, json=data)
        
        logger.info(f"æ”¶åˆ°å“åº”: çŠ¶æ€ç ={response.status_code}")
        
        if response.status_code == 200:
            result = response.json()
            output_file = result.get('output_file')
            input_text = result.get('input_text')
            process_time = result.get('process_time')
            
            logger.info(f"æ–‡å­—è½¬è¯­éŸ³æˆåŠŸ: è¾“å‡ºæ–‡ä»¶={output_file}, å¤„ç†æ—¶é—´={process_time}")
            
            if output_file and os.path.exists(output_file):
                with open(output_file, 'rb') as wav_file:
                    # è¯»å–wavæ–‡ä»¶ï¼Œå¹¶è½¬æ¢ä¸ºpcm
                    audio = AudioSegment.from_wav(wav_file)
                    audio_data = audio.raw_data
                    logger.info(f"è¯»å–éŸ³é¢‘æ–‡ä»¶æˆåŠŸ: å¤§å°={len(audio_data)}å­—èŠ‚")
                    return audio_data
            else:
                logger.error(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ: {output_file}")
                return None
        else:
            logger.error(f"æ–‡å­—è½¬è¯­éŸ³å¤±è´¥: çŠ¶æ€ç ={response.status_code}, å“åº”å†…å®¹={response.text}")
            return None
    except Exception as e:
        logger.error(f"æ–‡å­—è½¬è¯­éŸ³æ¥å£è°ƒç”¨å¤±è´¥: {str(e)}")
        import traceback
        logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
        return None


def use_f5tts(text, reference_audio_file):
    from gradio_client import Client, handle_file

    # è¯»å–reference_audio_fileåŒåçš„txtæ–‡ä»¶ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨ç©ºå­—ç¬¦ä¸²
    reference_text_file = reference_audio_file.replace(".wav", ".txt")
    if os.path.exists(reference_text_file):
        with open(reference_text_file, "r", encoding="utf-8") as f:
            reference_text = f.read()
    else:
        reference_text = ""

    client = Client(F5TTS_URL)
    output_audio_path, _, _, _ = client.predict(
            ref_audio_input=handle_file(reference_audio_file),
            ref_text_input=reference_text,
            gen_text_input=text,
            remove_silence=False,
            randomize_seed=True,
            seed_input=random.randint(0, 1000000),
            cross_fade_duration_slider=0.15,
            nfe_slider=32,
            speed_slider=0.8,
            api_name="/basic_tts"
    )
    if output_audio_path and os.path.exists(output_audio_path):
        with open(output_audio_path, 'rb') as wav_file:
            # è¯»å–wavæ–‡ä»¶ï¼Œå¹¶è½¬æ¢ä¸ºpcm
            audio = AudioSegment.from_wav(wav_file)
            audio_data = audio.raw_data
            logger.info(f"è¯»å–éŸ³é¢‘æ–‡ä»¶æˆåŠŸ: å¤§å°={len(audio_data)}å­—èŠ‚")
            return audio_data
    else:
        logger.error(f"è¾“å‡ºæ–‡ä»¶ä¸å­˜åœ¨æˆ–è·¯å¾„æ— æ•ˆ: {output_audio_path}")
        return None


def process_audio(raw_audio_data, session_id):
    """å¤„ç†éŸ³é¢‘æ•°æ®çš„å®Œæ•´æµç¨‹ï¼Œæ”¯æŒé€‰æ‹©ä¸åŒçš„å¤„ç†æ¨¡å¼"""
    global reference_audio_file
    
    try:
        # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶å
        timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        wav_file_path = os.path.join(AUDIO_DIR, f"audio_input_{session_id}_{timestamp}.wav")
        
        # å°†åŸå§‹æ•°æ®ä¿å­˜ä¸ºWAVæ–‡ä»¶
        with wave.open(wav_file_path, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(8000)
            wav_file.writeframes(raw_audio_data)
        logger.info(f"å·²ä¿å­˜WAVæ–‡ä»¶: {wav_file_path}")
        
        # MiniCPMæ¨¡å¼ï¼šç›´æ¥å°†éŸ³é¢‘å‘é€ç»™MiniCPMå¤„ç†
        if USE_MINICPM:
            global minicpm_client
            logger.info("ä½¿ç”¨MiniCPMæ¨¡å¼å¤„ç†éŸ³é¢‘...")
            audio_resp, txt_resp = minicpm_client.test_chunked_audio_processing(wav_file_path)
            return audio_resp, txt_resp

        # å¸¸è§„æ¨¡å¼ï¼šè¯­éŸ³è½¬æ–‡å­— -> èŠå¤© -> æ–‡å­—è½¬è¯­éŸ³
        else:
            logger.info("å¼€å§‹è¯­éŸ³è¯†åˆ«...")
            transcript = speech_to_text(wav_file_path)
            if not transcript:
                logger.warning("è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œæœªèƒ½è·å–æ–‡æœ¬")
                return None, "æŠ±æ­‰ï¼Œæ— æ³•è¯†åˆ«æ‚¨çš„è¯­éŸ³ã€‚"
            
            logger.info(f"è¯­éŸ³è¯†åˆ«ç»“æœ: {transcript}")
            
            # è·å–èŠå¤©å›å¤
            logger.info("æ­£åœ¨è·å–AIå›å¤...")
            ai_response = get_chat_response(transcript)
            if not ai_response:
                logger.warning("è·å–AIå›å¤å¤±è´¥")
                return None, "æŠ±æ­‰ï¼Œæ— æ³•è·å–AIå›å¤ã€‚"
            
            logger.info(f"AIå›å¤: {ai_response}")
            
            # å¦‚æœéœ€è¦è·³è¿‡TTSæ­¥éª¤
            if SKIP_TTS:
                logger.info("è·³è¿‡TTSæ­¥éª¤ï¼Œä»…è¿”å›æ–‡æœ¬å›å¤")
                return None, ai_response
            
            # ç”Ÿæˆè¯­éŸ³å›å¤
            logger.info("æ­£åœ¨ç”Ÿæˆè¯­éŸ³å›å¤...")
            if USE_F5TTS:
                audio_response = use_f5tts(ai_response, reference_audio_file)
            else:
                audio_response = text_to_speech(ai_response, reference_audio_file)

            # å¦‚æœæˆåŠŸç”Ÿæˆè¯­éŸ³
            if audio_response:
                logger.info(f"å·²ç”Ÿæˆè¯­éŸ³å›å¤: {len(audio_response)} å­—èŠ‚")
                return audio_response, ai_response
            
            logger.warning("è¯­éŸ³åˆæˆå¤±è´¥")
            return None, ai_response
            
    except Exception as e:
        logger.error(f"å¤„ç†éŸ³é¢‘æµç¨‹å‡ºé”™: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return None, "å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ã€‚"

def send_audio_chunk(ws, session_id_bytes, audio_chunk, retry_count=0):
    """å‘é€éŸ³é¢‘æ•°æ®å—ï¼Œå¸¦é‡è¯•æœºåˆ¶"""
    try:
        if not ws or not ws.sock or not ws.sock.connected:
            logger.error("WebSocketè¿æ¥å·²æ–­å¼€ï¼Œæ— æ³•å‘é€æ•°æ®")
            return False
            
        # æ·»åŠ ä¼šè¯IDå‰ç¼€
        data_with_session = session_id_bytes + audio_chunk
        ws.send(data_with_session, websocket.ABNF.OPCODE_BINARY)
        return True
    except websocket.WebSocketConnectionClosedException:
        if retry_count < WS_MAX_RETRIES:
            logger.warning(f"å‘é€æ•°æ®å¤±è´¥ï¼Œæ­£åœ¨é‡è¯• ({retry_count + 1}/{WS_MAX_RETRIES})")
            time.sleep(WS_RECONNECT_DELAY)
            return send_audio_chunk(ws, session_id_bytes, audio_chunk, retry_count + 1)
        else:
            logger.error("è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œå‘é€å¤±è´¥")
            return False
    except Exception as e:
        logger.error(f"å‘é€æ•°æ®æ—¶å‡ºé”™: {str(e)}")
        return False

def on_message(ws, message):
    """å¤„ç†æ¥æ”¶åˆ°çš„æ¶ˆæ¯"""
    try:
        # åˆ¤æ–­æ¶ˆæ¯ç±»å‹ - æ–‡æœ¬è¿˜æ˜¯äºŒè¿›åˆ¶
        if isinstance(message, str):
            pass

        elif isinstance(message, bytes):
            binary_data = message
            
            # ä»äºŒè¿›åˆ¶æ•°æ®ä¸­æå–ä¼šè¯IDï¼ˆå‰16å­—èŠ‚ï¼‰å’ŒéŸ³é¢‘æ•°æ®
            if len(binary_data) > 16:
                # æå–ä¼šè¯IDï¼ˆUUIDæ ¼å¼ï¼Œå­˜å‚¨åœ¨å‰16å­—èŠ‚ï¼‰
                global session_id_bytes
                session_id_bytes = binary_data[:16]
                raw_audio = binary_data[16:]
                
                try:
                    # å°†å­—èŠ‚è½¬æ¢ä¸ºUUIDå­—ç¬¦ä¸²
                    session_id = uuid.UUID(bytes=session_id_bytes).hex
                    # logger.info(f"æ”¶åˆ°éŸ³é¢‘æ•°æ®: ä¼šè¯ID = {session_id}, å¤§å° = {len(raw_audio)} å­—èŠ‚")
                    audio_response, text_response = process_audio(raw_audio, session_id)
                    
                    # å‘é€éŸ³é¢‘å›å¤ - åˆ†å—å‘é€
                    if audio_response:
                        chunk_size = WS_CHUNK_SIZE
                        total_chunks = (len(audio_response) + chunk_size - 1) // chunk_size
                        
                        for i in range(0, len(audio_response), chunk_size):
                            # æˆªå–ä¸€å—éŸ³é¢‘æ•°æ®
                            audio_chunk = audio_response[i:i+chunk_size]
                            # å‘é€æ•°æ®å—
                            if not send_audio_chunk(ws, session_id_bytes, audio_chunk):
                                logger.error(f"å‘é€éŸ³é¢‘æ•°æ®å—å¤±è´¥: {i//chunk_size + 1}/{total_chunks}")
                                break
                            logger.info(f"å‘é€éŸ³é¢‘å›å¤å—: ä¼šè¯ID = {session_id}, å—å¤§å° = {len(audio_chunk)} å­—èŠ‚, è¿›åº¦: {i//chunk_size + 1}/{total_chunks}")
                            # çŸ­æš‚æš‚åœï¼Œé¿å…å‘é€è¿‡å¿«
                            time.sleep(0.05)
                    
                    logger.info(f"ä¼šè¯ {session_id} å¤„ç†å®Œæˆ")
                    
                except ValueError:
                    logger.error("æ— æ³•è§£æä¼šè¯ID")
            else:
                logger.error(f"æ”¶åˆ°æ— æ•ˆçš„éŸ³é¢‘æ•°æ®: é•¿åº¦è¿‡çŸ­ ({len(binary_data)} å­—èŠ‚)")
    
    except Exception as e:
        import sys
        exc_type, exc_obj, exc_tb = sys.exc_info()
        line_number = exc_tb.tb_lineno
        logger.error(f"å¤„ç†æ¶ˆæ¯æ—¶å‡ºé”™: {str(e)}, å‡ºé”™è¡Œå·: {line_number}")

def start_websocket():
    global ws, reference_audio_file

    """å¯åŠ¨WebSocketè¿æ¥"""
    ws = websocket.WebSocketApp(
        WS_URL,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close,
        on_ping=on_ping,
        on_pong=on_pong
    )
    ws.on_open = on_open
    
    # å¯åŠ¨å¿ƒè·³çº¿ç¨‹
    heartbeat_thread = start_heartbeat(ws)

    # è®¾ç½®WebSocketé€‰é¡¹
    ws.run_forever(
        ping_interval=None,
        ping_timeout=None,
    )
    
    # ç­‰å¾…å¿ƒè·³çº¿ç¨‹ç»“æŸ
    if heartbeat_thread:
        heartbeat_thread.join()
            
def initialize_audio_categories():
    """åˆå§‹åŒ–éŸ³é¢‘åˆ†ç±»"""
    global AUDIO_CATEGORIES
    voice_cat_file = Path("voice_cat.json")
    
    if voice_cat_file.exists():
        # å¦‚æœvoice_cat.jsonæ–‡ä»¶å­˜åœ¨ï¼Œç›´æ¥åŠ è½½åˆ†ç±»ä¿¡æ¯
        with open(voice_cat_file, "r", encoding="utf-8") as f:
            AUDIO_CATEGORIES = json.load(f)
        logger.info("å·²ä»voice_cat.jsonåŠ è½½éŸ³é¢‘åˆ†ç±»ä¿¡æ¯")
    else:
        # å¦‚æœvoice_cat.jsonæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯»å–éŸ³é¢‘æ–‡ä»¶å¹¶ç”Ÿæˆåˆ†ç±»ä¿¡æ¯
        assets_dir = Path("/data/MegaTTS3/assets")
        male_dir = assets_dir / "ç”·"
        female_dir = assets_dir / "å¥³"
        
        AUDIO_CATEGORIES = {}
        
        # å¤„ç†"ç”·"ç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶
        if male_dir.exists() and male_dir.is_dir():
            for file_path in male_dir.glob("*.wav"):
                file_name = file_path.stem  # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                AUDIO_CATEGORIES[file_name] = str(file_path)
        
        # å¤„ç†"å¥³"ç›®å½•ä¸‹çš„éŸ³é¢‘æ–‡ä»¶
        if female_dir.exists() and female_dir.is_dir():
            for file_path in female_dir.glob("*.wav"):
                file_name = file_path.stem  # è·å–æ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
                AUDIO_CATEGORIES[file_name] = str(file_path)
        
        # å°†åˆ†ç±»ä¿¡æ¯ä¿å­˜åˆ°voice_cat.jsonæ–‡ä»¶
        with open(voice_cat_file, "w", encoding="utf-8") as f:
            json.dump(AUDIO_CATEGORIES, f, ensure_ascii=False, indent=4)
        logger.info("å·²ç”Ÿæˆå¹¶ä¿å­˜éŸ³é¢‘åˆ†ç±»ä¿¡æ¯åˆ°voice_cat.json")

def main():
    # å‚æ•°è§£æ
    parser = argparse.ArgumentParser(description="AIéŸ³é¢‘å¤„ç†å®¢æˆ·ç«¯")
    parser.add_argument("--use-minicpm", action="store_true", 
                      help="ä½¿ç”¨MiniCPMå¤§æ¨¡å‹è¿›è¡Œè¯­éŸ³å¤„ç†")
    parser.add_argument("--skip-tts", action="store_true", 
                      help="è·³è¿‡æ–‡æœ¬è½¬è¯­éŸ³æ­¥éª¤")
    parser.add_argument("--use-f5tts", action="store_true", 
                      help="ä½¿ç”¨f5ttsæ¥å£è¿›è¡Œè¯­éŸ³å¤„ç†")
    parser.add_argument("--use-uncensored", action="store_true", 
                      help="ä½¿ç”¨ä¸å®¡æŸ¥èŠå¤©æ¥å£")
    parser.add_argument("--voice-category", type=str, default="å¾¡å§é…éŸ³æš§æ˜§",
                      help="æŒ‡å®šéŸ³è‰²åç§°ï¼Œé»˜è®¤ä¸º'å¾¡å§é…éŸ³æš§æ˜§'")
    
    args = parser.parse_args()
    
    # è®¾ç½®å…¨å±€é…ç½®
    global USE_MINICPM, SKIP_TTS, USE_F5TTS, AUDIO_DIR, PROCESSED_DIR, USE_UNCENSORED
    USE_MINICPM = args.use_minicpm
    SKIP_TTS = args.skip_tts
    USE_F5TTS = args.use_f5tts
    USE_UNCENSORED = args.use_uncensored

    # åˆ›å»ºå¿…è¦çš„ç›®å½•
    setup_directories()
    
    # åˆå§‹åŒ–éŸ³é¢‘åˆ†ç±»
    initialize_audio_categories()
        
    # è®¾ç½®éŸ³è‰²åç§°
    global reference_audio_file
    reference_audio_file = AUDIO_CATEGORIES.get(args.voice_category, AUDIO_CATEGORIES["å¾¡å§é…éŸ³æš§æ˜§"])

    # æ£€æŸ¥æœåŠ¡çŠ¶æ€
    if not check_service_status(reference_audio_file):
        logger.error("æœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ")
        return

    # æ‰“å°å¯åŠ¨ä¿¡æ¯
    logger.info("=" * 50)
    logger.info("AIéŸ³é¢‘å¤„ç†å®¢æˆ·ç«¯å¯åŠ¨")
    logger.info(f"WebSocket URL: {WS_URL}")
    logger.info(f"éŸ³é¢‘æ–‡ä»¶ç›®å½•: {AUDIO_DIR}")
    logger.info(f"å¤„ç†æ–‡ä»¶ç›®å½•: {PROCESSED_DIR}")
    logger.info(f"ä½¿ç”¨MiniCPM: {USE_MINICPM}")
    logger.info(f"ä½¿ç”¨f5tts: {USE_F5TTS}")
    logger.info(f"ä½¿ç”¨ä¸å®¡æŸ¥èŠå¤©æ¥å£: {USE_UNCENSORED}")
    logger.info(f"è·³è¿‡TTS: {SKIP_TTS}")
    logger.info(f"éŸ³è‰²åç§°: {args.voice_category}")
    logger.info("=" * 50)
    
    # å¯åŠ¨å¼‚æ­¥å¾ªç¯
    asyncio.run(start_websocket())

def send_heartbeat(ws):
    """å‘é€å¿ƒè·³åŒ…ä¿æŒè¿æ¥æ´»è·ƒ"""
    try:
        if ws and ws.sock and ws.sock.connected:
            ws.send(json.dumps({"type": "heartbeat"}))
            logger.debug("å·²å‘é€å¿ƒè·³åŒ…")
    except Exception as e:
        logger.error(f"å‘é€å¿ƒè·³åŒ…å¤±è´¥: {str(e)}")

def start_heartbeat(ws):
    """å¯åŠ¨å¿ƒè·³çº¿ç¨‹"""
    def heartbeat_thread():
        while True:
            try:
                if ws and ws.sock and ws.sock.connected:
                    send_heartbeat(ws)
                time.sleep(WS_HEARTBEAT_INTERVAL)
            except Exception as e:
                logger.error(f"å¿ƒè·³çº¿ç¨‹å‡ºé”™: {str(e)}")
                break
    
    import threading
    heartbeat = threading.Thread(target=heartbeat_thread, daemon=True)
    heartbeat.start()
    return heartbeat

# é‡è¿å‚æ•°
max_reconnect_attempts = 10
reconnect_delay_seconds = 5
reconnect_attempt = 0

def on_error(ws, error):
    """å¤„ç†é”™è¯¯"""
    logger.error(f"WebSocketé”™è¯¯: {error}")

def on_close(ws, close_status_code, close_msg):
    """å¤„ç†è¿æ¥å…³é—­"""
    global reconnect_attempt, reconnect_delay_seconds, max_reconnect_attempts
    logger.warning(f"WebSocketè¿æ¥å·²å…³é—­: çŠ¶æ€ç ={close_status_code}, æ¶ˆæ¯={close_msg}")
    
    # å°è¯•é‡æ–°è¿æ¥
    if reconnect_attempt < max_reconnect_attempts:
        reconnect_attempt += 1
        logger.info(f"å°†åœ¨ {reconnect_delay_seconds} ç§’åå°è¯•é‡æ–°è¿æ¥...")
        time.sleep(reconnect_delay_seconds)
        # æŒ‡æ•°é€€é¿ç®—æ³•å¢åŠ é‡è¿å»¶è¿Ÿ
        reconnect_delay_seconds = min(60, reconnect_delay_seconds * 1.5)
        start_websocket()
    else:
        logger.error(f"è¾¾åˆ°æœ€å¤§é‡è¿æ¬¡æ•° ({max_reconnect_attempts})ï¼Œåœæ­¢é‡è¿")

def on_open(ws):
    """å¤„ç†è¿æ¥æˆåŠŸ"""
    global reconnect_attempt
    reconnect_attempt = 0
    
    # å‘é€AIåç«¯æ ‡è¯†
    ws.send(json.dumps({
        "client_type": "ai_backend"
    }))
    
    logger.info("WebSocketè¿æ¥å·²å»ºç«‹")

def on_ping(wsapp, message):
    print("Got a ping! A pong reply has already been automatically sent.")

def on_pong(wsapp, message):
    print("Got a pong! No need to respond")


if __name__ == "__main__":
    main()